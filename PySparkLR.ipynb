{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e32b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcb5ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/huy/spark-2.2.3-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a3df14",
   "metadata": {},
   "source": [
    "## Préparer les données pour Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652eff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Context</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f779405a550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# définir un SparkContext en local. Permet de travailler avec les RDD\n",
    "# sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Construire une session Spark\n",
    "# SparkSession est une couche supérieure à SparkContext\n",
    "spark = SparkSession.builder.appName('Spark Context').getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd007b9c",
   "metadata": {},
   "source": [
    "## Importer les données\n",
    "La base de données utilisée est Year Prediction MSD\n",
    "(https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD). Elle contient des caractéristiques audio de 515345\n",
    "chansons parues entre 1922 et 2011.\n",
    "Cette base de données contient 91 variables.\n",
    "\n",
    "L'objectif est d'estimer l'année de sortie avec une régression linéaire simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae712b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.csv(\"YearPredictionMSD.txt\")\n",
    "df_raw.sample(False, .00001, seed = 222).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6191c7",
   "metadata": {},
   "source": [
    "## Mise en forme de la base en format SVMLIB\n",
    "Pour pouvoir être utilisé par les algorithmes ML de SparkML le jeu de données doit être en format svmlib => dataframe avec deux colonnes label et features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f4cee",
   "metadata": {},
   "source": [
    "### Transformer toutes les colonnes à utiliser sous format numérique\n",
    "\n",
    "Le parsing de PySpark enregistre tous les variables en string.\n",
    "\n",
    "Il est possible d'automatiser le cast des colonnes avec la fonction col de pyspark.sql.functions\n",
    "\n",
    "Le principe est de nommer une colonne et de répéter l'opération avec une boucle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29bcd61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: double (nullable = true)\n",
      " |-- _c2: double (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: double (nullable = true)\n",
      " |-- _c5: double (nullable = true)\n",
      " |-- _c6: double (nullable = true)\n",
      " |-- _c7: double (nullable = true)\n",
      " |-- _c8: double (nullable = true)\n",
      " |-- _c9: double (nullable = true)\n",
      " |-- _c10: double (nullable = true)\n",
      " |-- _c11: double (nullable = true)\n",
      " |-- _c12: double (nullable = true)\n",
      " |-- _c13: double (nullable = true)\n",
      " |-- _c14: double (nullable = true)\n",
      " |-- _c15: double (nullable = true)\n",
      " |-- _c16: double (nullable = true)\n",
      " |-- _c17: double (nullable = true)\n",
      " |-- _c18: double (nullable = true)\n",
      " |-- _c19: double (nullable = true)\n",
      " |-- _c20: double (nullable = true)\n",
      " |-- _c21: double (nullable = true)\n",
      " |-- _c22: double (nullable = true)\n",
      " |-- _c23: double (nullable = true)\n",
      " |-- _c24: double (nullable = true)\n",
      " |-- _c25: double (nullable = true)\n",
      " |-- _c26: double (nullable = true)\n",
      " |-- _c27: double (nullable = true)\n",
      " |-- _c28: double (nullable = true)\n",
      " |-- _c29: double (nullable = true)\n",
      " |-- _c30: double (nullable = true)\n",
      " |-- _c31: double (nullable = true)\n",
      " |-- _c32: double (nullable = true)\n",
      " |-- _c33: double (nullable = true)\n",
      " |-- _c34: double (nullable = true)\n",
      " |-- _c35: double (nullable = true)\n",
      " |-- _c36: double (nullable = true)\n",
      " |-- _c37: double (nullable = true)\n",
      " |-- _c38: double (nullable = true)\n",
      " |-- _c39: double (nullable = true)\n",
      " |-- _c40: double (nullable = true)\n",
      " |-- _c41: double (nullable = true)\n",
      " |-- _c42: double (nullable = true)\n",
      " |-- _c43: double (nullable = true)\n",
      " |-- _c44: double (nullable = true)\n",
      " |-- _c45: double (nullable = true)\n",
      " |-- _c46: double (nullable = true)\n",
      " |-- _c47: double (nullable = true)\n",
      " |-- _c48: double (nullable = true)\n",
      " |-- _c49: double (nullable = true)\n",
      " |-- _c50: double (nullable = true)\n",
      " |-- _c51: double (nullable = true)\n",
      " |-- _c52: double (nullable = true)\n",
      " |-- _c53: double (nullable = true)\n",
      " |-- _c54: double (nullable = true)\n",
      " |-- _c55: double (nullable = true)\n",
      " |-- _c56: double (nullable = true)\n",
      " |-- _c57: double (nullable = true)\n",
      " |-- _c58: double (nullable = true)\n",
      " |-- _c59: double (nullable = true)\n",
      " |-- _c60: double (nullable = true)\n",
      " |-- _c61: double (nullable = true)\n",
      " |-- _c62: double (nullable = true)\n",
      " |-- _c63: double (nullable = true)\n",
      " |-- _c64: double (nullable = true)\n",
      " |-- _c65: double (nullable = true)\n",
      " |-- _c66: double (nullable = true)\n",
      " |-- _c67: double (nullable = true)\n",
      " |-- _c68: double (nullable = true)\n",
      " |-- _c69: double (nullable = true)\n",
      " |-- _c70: double (nullable = true)\n",
      " |-- _c71: double (nullable = true)\n",
      " |-- _c72: double (nullable = true)\n",
      " |-- _c73: double (nullable = true)\n",
      " |-- _c74: double (nullable = true)\n",
      " |-- _c75: double (nullable = true)\n",
      " |-- _c76: double (nullable = true)\n",
      " |-- _c77: double (nullable = true)\n",
      " |-- _c78: double (nullable = true)\n",
      " |-- _c79: double (nullable = true)\n",
      " |-- _c80: double (nullable = true)\n",
      " |-- _c81: double (nullable = true)\n",
      " |-- _c82: double (nullable = true)\n",
      " |-- _c83: double (nullable = true)\n",
      " |-- _c84: double (nullable = true)\n",
      " |-- _c85: double (nullable = true)\n",
      " |-- _c86: double (nullable = true)\n",
      " |-- _c87: double (nullable = true)\n",
      " |-- _c88: double (nullable = true)\n",
      " |-- _c89: double (nullable = true)\n",
      " |-- _c90: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# SparkSQL considère que toutes les variables sont du type string\n",
    "\n",
    "# pour ttes les colonnes de 1 à 91, cast en \"double\"\n",
    "exprs = [col(c).cast(\"double\") for c in df_raw.columns[1:91]]\n",
    "\n",
    "# la première colonne (l'année) est en int\n",
    "df_casted = df_raw.select(df_raw._c0.cast(\"int\"), *exprs)\n",
    "df = df_casted.sample(False, .1, seed = 222)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ecc2f",
   "metadata": {},
   "source": [
    "Vérfier s'il y a des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cd328b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "      <th>_c6</th>\n",
       "      <th>_c7</th>\n",
       "      <th>_c8</th>\n",
       "      <th>...</th>\n",
       "      <th>_c81</th>\n",
       "      <th>_c82</th>\n",
       "      <th>_c83</th>\n",
       "      <th>_c84</th>\n",
       "      <th>_c85</th>\n",
       "      <th>_c86</th>\n",
       "      <th>_c87</th>\n",
       "      <th>_c88</th>\n",
       "      <th>_c89</th>\n",
       "      <th>_c90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>...</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "      <td>515345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>1998.3970815667174</td>\n",
       "      <td>43.3871256257654</td>\n",
       "      <td>1.2895541971106774</td>\n",
       "      <td>8.658347088513471</td>\n",
       "      <td>1.164124465959709</td>\n",
       "      <td>-6.553600704557125</td>\n",
       "      <td>-9.521975199837009</td>\n",
       "      <td>-2.391089424909519</td>\n",
       "      <td>-1.7932355097264998</td>\n",
       "      <td>...</td>\n",
       "      <td>15.755406044028707</td>\n",
       "      <td>-73.46149977267599</td>\n",
       "      <td>41.54242155146567</td>\n",
       "      <td>37.9341187352939</td>\n",
       "      <td>0.31575127167237227</td>\n",
       "      <td>17.669213222656687</td>\n",
       "      <td>-26.31533596198668</td>\n",
       "      <td>4.4586411071806475</td>\n",
       "      <td>20.03513640768817</td>\n",
       "      <td>1.3291054377940912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>10.931046354331974</td>\n",
       "      <td>6.067558307506993</td>\n",
       "      <td>51.58035083014848</td>\n",
       "      <td>35.268584896496925</td>\n",
       "      <td>16.322789870993667</td>\n",
       "      <td>22.860785410540753</td>\n",
       "      <td>12.857751456762884</td>\n",
       "      <td>14.571873168680431</td>\n",
       "      <td>7.96382748276285</td>\n",
       "      <td>...</td>\n",
       "      <td>32.099634988385645</td>\n",
       "      <td>175.61888937668877</td>\n",
       "      <td>122.22879912808352</td>\n",
       "      <td>95.05063055805984</td>\n",
       "      <td>16.161764077993315</td>\n",
       "      <td>114.42790475450818</td>\n",
       "      <td>173.97733604430147</td>\n",
       "      <td>13.346556689429212</td>\n",
       "      <td>185.55824667696422</td>\n",
       "      <td>22.08857637885433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>1922</td>\n",
       "      <td>1.749</td>\n",
       "      <td>-337.0925</td>\n",
       "      <td>-301.00506</td>\n",
       "      <td>-154.18358</td>\n",
       "      <td>-181.95337</td>\n",
       "      <td>-81.79429</td>\n",
       "      <td>-188.214</td>\n",
       "      <td>-72.50385</td>\n",
       "      <td>...</td>\n",
       "      <td>-437.72203</td>\n",
       "      <td>-4402.37644</td>\n",
       "      <td>-1810.68919</td>\n",
       "      <td>-3098.35031</td>\n",
       "      <td>-341.78912</td>\n",
       "      <td>-3168.92457</td>\n",
       "      <td>-4319.99232</td>\n",
       "      <td>-236.03926</td>\n",
       "      <td>-7458.37815</td>\n",
       "      <td>-381.42443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2011</td>\n",
       "      <td>61.97014</td>\n",
       "      <td>384.06573</td>\n",
       "      <td>322.85143</td>\n",
       "      <td>335.77182</td>\n",
       "      <td>262.06887</td>\n",
       "      <td>166.23689</td>\n",
       "      <td>172.40268</td>\n",
       "      <td>126.74127</td>\n",
       "      <td>...</td>\n",
       "      <td>840.97338</td>\n",
       "      <td>4469.45487</td>\n",
       "      <td>3210.7017</td>\n",
       "      <td>1734.07969</td>\n",
       "      <td>260.5449</td>\n",
       "      <td>3662.06565</td>\n",
       "      <td>2833.60895</td>\n",
       "      <td>463.4195</td>\n",
       "      <td>7393.39844</td>\n",
       "      <td>677.89963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 _c0                _c1                 _c2  \\\n",
       "0   count              515345             515345              515345   \n",
       "1    mean  1998.3970815667174   43.3871256257654  1.2895541971106774   \n",
       "2  stddev  10.931046354331974  6.067558307506993   51.58035083014848   \n",
       "3     min                1922              1.749           -337.0925   \n",
       "4     max                2011           61.97014           384.06573   \n",
       "\n",
       "                  _c3                 _c4                 _c5  \\\n",
       "0              515345              515345              515345   \n",
       "1   8.658347088513471   1.164124465959709  -6.553600704557125   \n",
       "2  35.268584896496925  16.322789870993667  22.860785410540753   \n",
       "3          -301.00506          -154.18358          -181.95337   \n",
       "4           322.85143           335.77182           262.06887   \n",
       "\n",
       "                  _c6                 _c7                  _c8  ...  \\\n",
       "0              515345              515345               515345  ...   \n",
       "1  -9.521975199837009  -2.391089424909519  -1.7932355097264998  ...   \n",
       "2  12.857751456762884  14.571873168680431     7.96382748276285  ...   \n",
       "3           -81.79429            -188.214            -72.50385  ...   \n",
       "4           166.23689           172.40268            126.74127  ...   \n",
       "\n",
       "                 _c81                _c82                _c83  \\\n",
       "0              515345              515345              515345   \n",
       "1  15.755406044028707  -73.46149977267599   41.54242155146567   \n",
       "2  32.099634988385645  175.61888937668877  122.22879912808352   \n",
       "3          -437.72203         -4402.37644         -1810.68919   \n",
       "4           840.97338          4469.45487           3210.7017   \n",
       "\n",
       "                _c84                 _c85                _c86  \\\n",
       "0             515345               515345              515345   \n",
       "1   37.9341187352939  0.31575127167237227  17.669213222656687   \n",
       "2  95.05063055805984   16.161764077993315  114.42790475450818   \n",
       "3        -3098.35031           -341.78912         -3168.92457   \n",
       "4         1734.07969             260.5449          3662.06565   \n",
       "\n",
       "                 _c87                _c88                _c89  \\\n",
       "0              515345              515345              515345   \n",
       "1  -26.31533596198668  4.4586411071806475   20.03513640768817   \n",
       "2  173.97733604430147  13.346556689429212  185.55824667696422   \n",
       "3         -4319.99232          -236.03926         -7458.37815   \n",
       "4          2833.60895            463.4195          7393.39844   \n",
       "\n",
       "                 _c90  \n",
       "0              515345  \n",
       "1  1.3291054377940912  \n",
       "2   22.08857637885433  \n",
       "3          -381.42443  \n",
       "4           677.89963  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d195650",
   "metadata": {},
   "source": [
    "La Base de Données doit être un DF avec 2 colonnes\n",
    "- colonne 1: le label contenant la valeur à prédire\n",
    "- colonne 2: features contenant les variables explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636d5813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "| 2001|[49.94357,21.4711...|\n",
      "| 2001|[48.73215,18.4293...|\n",
      "| 2001|[50.95714,31.8560...|\n",
      "| 2001|[48.2475,-1.89837...|\n",
      "| 2001|[50.9702,42.20998...|\n",
      "| 2001|[50.54767,0.31568...|\n",
      "| 2001|[50.57546,33.1784...|\n",
      "| 2001|[48.26892,8.97526...|\n",
      "| 2001|[49.75468,33.9958...|\n",
      "| 2007|[45.17809,46.3423...|\n",
      "| 2008|[39.13076,-23.017...|\n",
      "| 2002|[37.66498,-34.059...|\n",
      "| 2004|[26.51957,-148.15...|\n",
      "| 2003|[37.68491,-26.841...|\n",
      "| 1999|[39.11695,-8.2976...|\n",
      "| 2003|[35.05129,-67.977...|\n",
      "| 2002|[33.63129,-96.149...|\n",
      "| 1992|[41.38639,-20.786...|\n",
      "| 1997|[37.45034,11.4261...|\n",
      "| 1987|[39.71092,-4.928,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "\n",
    "# La fonction DenseVector permet de regrouper plusieurs variables en une seule.\n",
    "\n",
    "# créer un rdd à partir de la df en séparant la colonne à prédire (colonne 0) des autres variables \n",
    "rdd_ml = df.rdd.map(lambda x: (x[0], DenseVector(x[1:])))\n",
    "\n",
    "# puis le remettre le rdd sous formt df en nommant les deux colonnes\n",
    "df_ml = spark.createDataFrame(rdd_ml, ['label', 'features'])\n",
    "\n",
    "df_ml.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c10b71",
   "metadata": {},
   "source": [
    "## Séparer la Base de Données en deux: train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7aa3bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "| 1922|[39.96727,41.8845...|\n",
      "| 1922|[40.96435,64.5129...|\n",
      "| 1922|[41.02674,31.1615...|\n",
      "| 1926|[27.59278,-179.29...|\n",
      "| 1926|[31.08514,-146.64...|\n",
      "| 1926|[31.66611,-174.42...|\n",
      "| 1927|[26.05789,-213.38...|\n",
      "| 1927|[32.80382,-165.04...|\n",
      "| 1927|[34.45029,-124.70...|\n",
      "| 1927|[35.6517,-137.696...|\n",
      "| 1927|[36.72843,-73.046...|\n",
      "| 1927|[38.55108,-68.016...|\n",
      "| 1928|[32.33556,-200.12...|\n",
      "| 1928|[34.5108,-241.287...|\n",
      "| 1928|[34.74756,-60.680...|\n",
      "| 1928|[35.49673,-230.03...|\n",
      "| 1928|[36.89361,-74.548...|\n",
      "| 1928|[37.09369,-119.24...|\n",
      "| 1929|[22.43376,-106.81...|\n",
      "| 1929|[28.86846,-134.80...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(train, test) = df_ml.randomSplit([.8, .2], seed = 222)\n",
    "\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "617791ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set count: 412014\n",
      "Test data set count: 103331\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data set count: \" + str(train.count()))\n",
    "print(\"Test data set count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44cd3c",
   "metadata": {},
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "clf = RandomForestClassifier(labelCol='label', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = clf.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94fe79",
   "metadata": {},
   "source": [
    "## Régression linéaire \n",
    "Cette fonction permet d'e!ectuer une régression linéaire de façon distribuée et e!ectue les calculs sur les di!érents clusters prédéfinis dans la SparkSession, quel que soit leur nombre ou la taille de la base de données\n",
    "\n",
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html#pyspark.ml.regression.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b454ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# créer la fonction avec les paramètres adaptés\n",
    "lr = LinearRegression(labelCol='label', featuresCol='features')\n",
    "\n",
    "# appliquer la fonction aux données d'entraînement\n",
    "linearModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d588a30",
   "metadata": {},
   "source": [
    "### La méthode transform permet d'effectuer des prédictions en utilisant le modèle précédemment entraîné sur les données test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983b6f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+\n",
      "|label|            features|        prediction|\n",
      "+-----+--------------------+------------------+\n",
      "| 1922|[43.68703,39.4915...|1992.6693394653053|\n",
      "| 1922|[46.15136,66.0833...|1997.8178673921616|\n",
      "| 1926|[30.93702,-134.48...|1985.6612526954189|\n",
      "| 1926|[33.56654,-108.02...| 1984.351345826122|\n",
      "| 1927|[32.05226,-212.58...|1999.4042605274938|\n",
      "| 1928|[23.30325,-161.61...| 1992.270116806092|\n",
      "| 1928|[31.04544,-226.47...|1995.3462977548033|\n",
      "| 1929|[26.64447,-72.858...|1982.1302096572354|\n",
      "| 1929|[35.07089,-67.509...|1992.8264528847812|\n",
      "| 1929|[35.52744,-147.45...|1989.2155707594618|\n",
      "| 1929|[36.34358,-137.32...|1985.2056367144933|\n",
      "| 1929|[37.26627,-54.121...|1986.9368287206887|\n",
      "| 1929|[37.30241,-69.688...|1986.1068673930301|\n",
      "| 1929|[38.38185,-55.354...|1994.1931199143758|\n",
      "| 1930|[34.14566,-89.762...|1985.2599625914706|\n",
      "| 1930|[38.10036,-65.865...|1988.6101254063515|\n",
      "| 1930|[39.41802,-73.499...|1984.9167263500447|\n",
      "| 1930|[41.08332,-93.379...|  1989.19393371468|\n",
      "| 1937|[31.33392,-150.96...| 1988.412376328371|\n",
      "| 1937|[34.39015,-117.43...|1989.8691642376439|\n",
      "+-----+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = linearModel.transform(test)\n",
    "\n",
    "predicted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e7a2c",
   "metadata": {},
   "source": [
    "## Evaluer le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34afaa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.549170611597843\n",
      "R2: 0.2370793808427959\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {linearModel.summary.rootMeanSquaredError}\")\n",
    "print(f\"R2: {linearModel.summary.r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6fc28",
   "metadata": {},
   "source": [
    "Bien que la RMSE indique une erreur moyenne relativement faible (inférieur à 10), le R2 reste très faible\n",
    "(inférieur à 0.25). On peut donc penser que le modèle de régression est dans ce cas un mauvais indicateur de\n",
    "la décennie dans laquelle la chanson a été composée.\n",
    "Il faut utiliser un autre modèle.\n",
    "\n",
    "Ne pas oublier de femer la session spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a43660dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e61613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
